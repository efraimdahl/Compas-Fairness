{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvGd4YgtppjR"
      },
      "source": [
        "## Submission instructions\n",
        "\n",
        "All code that you write should be in this notebook. Please include your names and student numbers. You have to submit two files:\n",
        "\n",
        "* This notebook with your code added. Make sure to add enough documentation.\n",
        "* A short report, around 2 pages including any figures and/or tables (it is likely that you won't need the full 2 pages). Use [this template](https://www.overleaf.com/read/mvskntycrckw).\n",
        "\n",
        "For questions, make use of the \"Lab\" session (see schedule).\n",
        "Questions can also be posted to the MS teams channel called \"Lab\".\n",
        "\n",
        "**Note:** You are free to make use of Python libraries (e.g., numpy, sklearn, etc.) except any *fairness* libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bii8KkkLUg5i"
      },
      "source": [
        "#### Name and student numbers\n",
        "...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ni3V-7iqA6X"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "In this assignment we are going to use the **COMPAS** dataset.\n",
        "\n",
        "If you haven't done so already, take a look at this article: https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.\n",
        "For background on the dataset, see https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm.\n",
        "\n",
        "**Reading in the COMPAS dataset**\n",
        "\n",
        "The dataset can be downloaded here: https://github.com/propublica/compas-analysis/blob/master/compas-scores-two-years.csv\n",
        "\n",
        "For this assignment, we focus on the protected attribute *race*.\n",
        "\n",
        "The label (the variable we want to be able to predict) represents recidivism, which is defined as a new arrest within 2 years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajLXEdx6plgP",
        "outputId": "a65bf36a-1bc6-488f-accc-7bd9b24ca411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-25 07:21:03--  https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2546489 (2.4M) [text/plain]\n",
            "Saving to: ‘compas-scores-two-years.csv’\n",
            "\n",
            "compas-scores-two-y 100%[===================>]   2.43M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-04-25 07:21:03 (35.4 MB/s) - ‘compas-scores-two-years.csv’ saved [2546489/2546489]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -c https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "AaT9DQwwpqkx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import random\n",
        "\n",
        "def set_seed(seed):\n",
        "    #set all random seeds\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    return None\n",
        "\n",
        "SEED = 42\n",
        "set_seed(SEED)\n",
        "\n",
        "compas_data = pd.read_csv('compas-scores-two-years.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsidUr4Bz-gZ"
      },
      "source": [
        "We apply several data preprocessing steps, including only retaining Caucasians and African Americans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "vs2eRxdgrHrt"
      },
      "outputs": [],
      "source": [
        "compas_data = compas_data[(compas_data.days_b_screening_arrest <= 30)\n",
        "            & (compas_data.days_b_screening_arrest >= -30)\n",
        "            & (compas_data.is_recid != -1)\n",
        "            & (compas_data.c_charge_degree != 'O')\n",
        "            & (compas_data.score_text != 'N/A')\n",
        "            & ((compas_data.race == 'Caucasian') | (compas_data.race == 'African-American'))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5IwB6Rz2zIS"
      },
      "source": [
        "Take a look at the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMM-MYdstObf",
        "outputId": "0bf826a7-bf28-433b-ea6a-b21c5f3f1fe6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>first</th>\n",
              "      <th>last</th>\n",
              "      <th>compas_screening_date</th>\n",
              "      <th>sex</th>\n",
              "      <th>dob</th>\n",
              "      <th>age</th>\n",
              "      <th>age_cat</th>\n",
              "      <th>race</th>\n",
              "      <th>...</th>\n",
              "      <th>v_decile_score</th>\n",
              "      <th>v_score_text</th>\n",
              "      <th>v_screening_date</th>\n",
              "      <th>in_custody</th>\n",
              "      <th>out_custody</th>\n",
              "      <th>priors_count.1</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>event</th>\n",
              "      <th>two_year_recid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>kevon dixon</td>\n",
              "      <td>kevon</td>\n",
              "      <td>dixon</td>\n",
              "      <td>2013-01-27</td>\n",
              "      <td>Male</td>\n",
              "      <td>1982-01-22</td>\n",
              "      <td>34</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>African-American</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-01-27</td>\n",
              "      <td>2013-01-26</td>\n",
              "      <td>2013-02-05</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>159</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>ed philo</td>\n",
              "      <td>ed</td>\n",
              "      <td>philo</td>\n",
              "      <td>2013-04-14</td>\n",
              "      <td>Male</td>\n",
              "      <td>1991-05-14</td>\n",
              "      <td>24</td>\n",
              "      <td>Less than 25</td>\n",
              "      <td>African-American</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-04-14</td>\n",
              "      <td>2013-06-16</td>\n",
              "      <td>2013-06-16</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8</td>\n",
              "      <td>edward riddle</td>\n",
              "      <td>edward</td>\n",
              "      <td>riddle</td>\n",
              "      <td>2014-02-19</td>\n",
              "      <td>Male</td>\n",
              "      <td>1974-07-23</td>\n",
              "      <td>41</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>Low</td>\n",
              "      <td>2014-02-19</td>\n",
              "      <td>2014-03-31</td>\n",
              "      <td>2014-04-18</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10</td>\n",
              "      <td>elizabeth thieme</td>\n",
              "      <td>elizabeth</td>\n",
              "      <td>thieme</td>\n",
              "      <td>2014-03-16</td>\n",
              "      <td>Female</td>\n",
              "      <td>1976-06-03</td>\n",
              "      <td>39</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Low</td>\n",
              "      <td>2014-03-16</td>\n",
              "      <td>2014-03-15</td>\n",
              "      <td>2014-03-18</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>747</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>14</td>\n",
              "      <td>benjamin franc</td>\n",
              "      <td>benjamin</td>\n",
              "      <td>franc</td>\n",
              "      <td>2013-11-26</td>\n",
              "      <td>Male</td>\n",
              "      <td>1988-06-01</td>\n",
              "      <td>27</td>\n",
              "      <td>25 - 45</td>\n",
              "      <td>Caucasian</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>Low</td>\n",
              "      <td>2013-11-26</td>\n",
              "      <td>2013-11-25</td>\n",
              "      <td>2013-11-26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>857</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 53 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    id              name      first    last compas_screening_date     sex  \\\n",
              "1    3       kevon dixon      kevon   dixon            2013-01-27    Male   \n",
              "2    4          ed philo         ed   philo            2013-04-14    Male   \n",
              "6    8     edward riddle     edward  riddle            2014-02-19    Male   \n",
              "8   10  elizabeth thieme  elizabeth  thieme            2014-03-16  Female   \n",
              "10  14    benjamin franc   benjamin   franc            2013-11-26    Male   \n",
              "\n",
              "           dob  age       age_cat              race  ...  v_decile_score  \\\n",
              "1   1982-01-22   34       25 - 45  African-American  ...               1   \n",
              "2   1991-05-14   24  Less than 25  African-American  ...               3   \n",
              "6   1974-07-23   41       25 - 45         Caucasian  ...               2   \n",
              "8   1976-06-03   39       25 - 45         Caucasian  ...               1   \n",
              "10  1988-06-01   27       25 - 45         Caucasian  ...               4   \n",
              "\n",
              "    v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
              "1            Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
              "2            Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
              "6            Low        2014-02-19  2014-03-31   2014-04-18              14   \n",
              "8            Low        2014-03-16  2014-03-15   2014-03-18               0   \n",
              "10           Low        2013-11-26  2013-11-25   2013-11-26               0   \n",
              "\n",
              "   start  end event two_year_recid  \n",
              "1      9  159     1              1  \n",
              "2      0   63     0              1  \n",
              "6      5   40     1              1  \n",
              "8      2  747     0              0  \n",
              "10     0  857     0              0  \n",
              "\n",
              "[5 rows x 53 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compas_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vKapT6FtmvJ"
      },
      "source": [
        "Now take a look at the distribution of the protected attribute `race` and the distribution of our outcome variable `two_year_recid`.\n",
        "\n",
        "**Note:** in the context of fair machine learning, the favorable label here is no recidivism, i.e., ```two_year_recid = 0```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh2oM2yptnjR",
        "outputId": "f89ff857-41d9-4a8c-d236-6fd4af65f177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of instances per race category:\n",
            "race              two_year_recid\n",
            "African-American  1                 1661\n",
            "                  0                 1514\n",
            "Caucasian         0                 1281\n",
            "                  1                  822\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Number of instances per race category:')\n",
        "print(compas_data[['race', 'two_year_recid']].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "636Yopp6wNtY"
      },
      "source": [
        "## Data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS3g2NT98dY_"
      },
      "source": [
        "### **1. Exploration**\n",
        "\n",
        "Perform an exploratory analysis of your data and describe the results in your report.\n",
        "Include at least the following:\n",
        "\n",
        "1. The size of your data;\n",
        "2. The size of the protected attribute classes;\n",
        "3. The base rates (the probability of a favorable outcome for the two protected attribute classes);\n",
        "4. The base rates for the combination of both race and sex categories. What do you see?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k6FESAE1VmPu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-mxqnnUcaGc"
      },
      "source": [
        "### **2. Performance measures**\n",
        "\n",
        "You will have to measure the performance and fairness of different classifiers in question 5. The performance will be calculated with the precision, recall, F1 and accuracy.\n",
        "Additionally, you will have to calculate the statistical/demographic parity, the true positive rate (recall) and false positive rate per race group.\n",
        "\n",
        "Make sure that you are able to calculate these metrics in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "IAO99gf2caZT"
      },
      "outputs": [],
      "source": [
        "# Your code for the performance measures\n",
        "def metrics(df, groups='race', disparity_threshold=0.8):\n",
        "    '''\n",
        "    df: pandas DataFrame, must contain columns two_year_recid, prediction and column specified in groups (default \"race\")\n",
        "    returns: dictionary with performance metrics\n",
        "    '''\n",
        "    performance = {}\n",
        "    performance['accuracy'] = accuracy_score(df['two_year_recid'], df['prediction'])\n",
        "    performance['precision'], performance['recall'], performance['f1'], _ = precision_recall_fscore_support(df['two_year_recid'], df['prediction'], average='binary')\n",
        "    aa_group = df[df[groups] == 'African-American']\n",
        "    cc_group = df[df[groups] == 'Caucasian']\n",
        "    P_pos_aa = aa_group[aa_group['prediction'] == 0].shape[0] / (aa_group.shape[0] + 1e-6)\n",
        "    P_pos_cc = cc_group[cc_group['prediction'] == 0].shape[0] / (cc_group.shape[0] + 1e-6)\n",
        "    performance['disparate_impact'] = P_pos_aa/P_pos_cc\n",
        "    performance['demographic_parity'] = P_pos_aa/P_pos_cc < disparity_threshold\n",
        "\n",
        "    TP_rate_aa = aa_group[(aa_group['prediction'] == 0) & (aa_group['two_year_recid'] == 0)].shape[0] / (aa_group[aa_group['two_year_recid'] == 0].shape[0] + 1e-6)\n",
        "    TP_rate_cc = cc_group[(cc_group['prediction'] == 0) & (cc_group['two_year_recid'] == 0)].shape[0] / (cc_group[cc_group['two_year_recid'] == 0].shape[0] + 1e-6)\n",
        "\n",
        "    performance['African-American_true_positive_rate'] = TP_rate_aa\n",
        "    performance['Caucasian_true_positive_rate'] = TP_rate_cc\n",
        "    performance['equal_opportunity'] = TP_rate_aa/TP_rate_cc < disparity_threshold\n",
        "\n",
        "    FP_rate_aa = aa_group[(aa_group['prediction'] == 0) & (aa_group['two_year_recid'] == 1)].shape[0] / (aa_group[aa_group['two_year_recid'] == 0].shape[0] + 1e-6)\n",
        "    FP_rate_cc = cc_group[(cc_group['prediction'] == 0) & (cc_group['two_year_recid'] == 1)].shape[0] / (cc_group[cc_group['two_year_recid'] == 0].shape[0] + 1e-6)\n",
        "\n",
        "    performance['African-American_false_positive_rate'] = FP_rate_aa\n",
        "    performance['Caucasian_false_positive_rate'] = FP_rate_cc\n",
        "    performance['predictive_parity'] = FP_rate_aa/FP_rate_cc < disparity_threshold\n",
        "\n",
        "    # round to 4 decimal places\n",
        "    for key in performance.keys():\n",
        "        performance[key] = round(performance[key], 4)\n",
        "\n",
        "    return performance  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.5064,\n",
              " 'precision': 0.4768,\n",
              " 'recall': 0.5046,\n",
              " 'f1': 0.4903,\n",
              " 'disparate_impact': 0.9967,\n",
              " 'demographic_parity': 0,\n",
              " 'African-American_true_positive_rate': 0.5099,\n",
              " 'Caucasian_true_positive_rate': 0.5059,\n",
              " 'equal_opportunity': 0,\n",
              " 'African-American_false_positive_rate': 0.5416,\n",
              " 'Caucasian_false_positive_rate': 0.3201,\n",
              " 'predictive_parity': 0}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# example usage\n",
        "compas_data['prediction'] = np.random.randint(0, 2, compas_data.shape[0])\n",
        "\n",
        "metrics(compas_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n51Bdpy59vhy"
      },
      "source": [
        "### **3. Prepare the data**\n",
        "For the classifiers in question 5, the input of the model can only contain numerical values, it is therefore important to convert the strings in the columns (features) of interest of the `compas_data` to floats or integers.\n",
        "\n",
        "The columns of interest are features that you think will be informative or interesting in predicting the outcome variable.\n",
        "\n",
        "Use the cell below to explore which of the compas variables you need to convert to be able to use them for the classifiers. Also make sure that you understand the relationship between categorical and numerical values.\n",
        "\n",
        "Then generate a new dataframe with your selected features in the right encoding (also make sure to include `two_year_recid`). You can implement this yourself, or use the `LabelEncoder` from `sklearn`.\n",
        "\n",
        "**Note:** you do not need to convert all columns/features, only the ones you are interested in. Please include in your **report** a short motivation (one-two sentence) per feature why you think this is informative or interesting to take into account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "2G0-QxbH95rX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initial dataset dat atypes id                           int64\n",
            "name                        object\n",
            "first                       object\n",
            "last                        object\n",
            "compas_screening_date       object\n",
            "sex                         object\n",
            "dob                         object\n",
            "age                          int64\n",
            "age_cat                     object\n",
            "race                        object\n",
            "juv_fel_count                int64\n",
            "decile_score                 int64\n",
            "juv_misd_count               int64\n",
            "juv_other_count              int64\n",
            "priors_count                 int64\n",
            "days_b_screening_arrest    float64\n",
            "c_jail_in                   object\n",
            "c_jail_out                  object\n",
            "c_case_number               object\n",
            "c_offense_date              object\n",
            "c_arrest_date               object\n",
            "c_days_from_compas         float64\n",
            "c_charge_degree             object\n",
            "c_charge_desc               object\n",
            "is_recid                     int64\n",
            "r_case_number               object\n",
            "r_charge_degree             object\n",
            "r_days_from_arrest         float64\n",
            "r_offense_date              object\n",
            "r_charge_desc               object\n",
            "r_jail_in                   object\n",
            "r_jail_out                  object\n",
            "violent_recid              float64\n",
            "is_violent_recid             int64\n",
            "vr_case_number              object\n",
            "vr_charge_degree            object\n",
            "vr_offense_date             object\n",
            "vr_charge_desc              object\n",
            "type_of_assessment          object\n",
            "decile_score.1               int64\n",
            "score_text                  object\n",
            "screening_date              object\n",
            "v_type_of_assessment        object\n",
            "v_decile_score               int64\n",
            "v_score_text                object\n",
            "v_screening_date            object\n",
            "in_custody                  object\n",
            "out_custody                 object\n",
            "priors_count.1               int64\n",
            "start                        int64\n",
            "end                          int64\n",
            "event                        int64\n",
            "two_year_recid               int64\n",
            "prediction                   int64\n",
            "dtype: object\n",
            "list of non numerical features: Index(['name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
            "       'age_cat', 'race', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
            "       'c_offense_date', 'c_arrest_date', 'c_charge_degree', 'c_charge_desc',\n",
            "       'r_case_number', 'r_charge_degree', 'r_offense_date', 'r_charge_desc',\n",
            "       'r_jail_in', 'r_jail_out', 'vr_case_number', 'vr_charge_degree',\n",
            "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment', 'score_text',\n",
            "       'screening_date', 'v_type_of_assessment', 'v_score_text',\n",
            "       'v_screening_date', 'in_custody', 'out_custody'],\n",
            "      dtype='object')\n",
            "list of categorical features: ['age_cat', 'v_screening_date', 'score_text', 'r_charge_degree', 'v_score_text', 'c_charge_desc', 'c_charge_degree', 'last', 'type_of_assessment', 'race', 'r_charge_desc', 'v_type_of_assessment', 'sex', 'name', 'first']\n"
          ]
        }
      ],
      "source": [
        "# Your code to prepare the data\n",
        "# print data type of each column\n",
        "print('initial dataset dat atypes', compas_data.dtypes)\n",
        "\n",
        "obj_features = compas_data.select_dtypes(include='object').columns\n",
        "print('list of non numerical features:', obj_features)\n",
        "\n",
        "date_time_features = ['compas_screening_date', 'dob', 'c_jail_in', 'c_jail_out',\n",
        "       'c_offense_date', 'c_arrest_date', 'r_offense_date',\n",
        "       'r_jail_in', 'r_jail_out', 'screening_date', 'in_custody', 'out_custody']\n",
        "\n",
        "non_train_features = ['id', 'c_case_number', 'r_case_number', 'vr_case_number', 'vr_charge_degree', 'vr_offense_date', 'vr_charge_desc']\n",
        "\n",
        "categorical_features = list(set(obj_features) - set(date_time_features) - set(non_train_features))\n",
        "categorical_features\n",
        "print('list of categorical features:', categorical_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "compas_screening_date       0\n",
              "dob                         0\n",
              "c_jail_in                   0\n",
              "c_jail_out                  0\n",
              "c_offense_date            689\n",
              "c_arrest_date            4589\n",
              "r_offense_date           2631\n",
              "r_jail_in                3497\n",
              "r_jail_out               3497\n",
              "screening_date              0\n",
              "in_custody                  0\n",
              "out_custody                 0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compas_data[date_time_features].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "c_jail_in                     0\n",
              "is_violent_recid              0\n",
              "start                         0\n",
              "r_jail_in                     0\n",
              "r_jail_out_missing            0\n",
              "v_decile_score                0\n",
              "r_days_from_arrest         2809\n",
              "c_jail_out                    0\n",
              "c_arrest_date_missing         0\n",
              "out_custody                   0\n",
              "juv_fel_count                 0\n",
              "in_custody                    0\n",
              "decile_score                  0\n",
              "age                           0\n",
              "r_jail_in_missing             0\n",
              "days_b_screening_arrest       0\n",
              "c_offense_date_missing        0\n",
              "decile_score.1                0\n",
              "priors_count                  0\n",
              "screening_date                0\n",
              "c_offense_date                0\n",
              "is_recid                      0\n",
              "c_days_from_compas            0\n",
              "violent_recid              4222\n",
              "r_jail_out                    0\n",
              "priors_count.1                0\n",
              "r_offense_date_missing        0\n",
              "c_arrest_date                 0\n",
              "juv_other_count               0\n",
              "event                         0\n",
              "juv_misd_count                0\n",
              "r_offense_date                0\n",
              "end                           0\n",
              "compas_screening_date         0\n",
              "prediction                    0\n",
              "dob                           0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "non_ohe_ftrs = list(set(X_train.columns) - set(processor.encoder.get_feature_names_out()))\n",
        "X_train[non_ohe_ftrs].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dt_to_seconds(series):\n",
        "    series = pd.to_datetime(series)\n",
        "    return (series - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
        "\n",
        "class FeaturePreprocessor:\n",
        "    def __init__(self, categorical_features, date_time_features, non_train_features, min_freq=0.01):\n",
        "        self.categorical_features = categorical_features\n",
        "        self.date_time_features = date_time_features\n",
        "        self.non_train_features = non_train_features\n",
        "        self.scaler = StandardScaler()\n",
        "        self.encoder = OneHotEncoder(sparse_output=False, min_frequency=min_freq)\n",
        "\n",
        "    def fit_transform(self, X, full_cetagorical_df):\n",
        "        X = X.copy()\n",
        "        X = X.drop(columns=self.non_train_features)\n",
        "        self.numerical_features = list(set(X.columns) - set(self.categorical_features))\n",
        "        for ftr in self.date_time_features:\n",
        "            X[ftr] = dt_to_seconds(X[ftr])\n",
        "            if X[ftr].isna().sum() > 0:\n",
        "                new_ftr = ftr + '_missing'\n",
        "                X[new_ftr] = X[ftr].isna().astype(int)\n",
        "                X[ftr] = X[ftr].fillna(-1)\n",
        "        \n",
        "        X[self.numerical_features] = self.scaler.fit_transform(X[self.numerical_features])\n",
        "        self.encoder.fit(full_cetagorical_df)\n",
        "        ohe_feature_names = self.encoder.get_feature_names_out()\n",
        "        X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
        "        X = X.drop(columns=self.categorical_features)\n",
        "        for col in ['r_days_from_arrest', 'violent_recid']:\n",
        "            if col in X.columns:\n",
        "                X[col] = X[col].fillna(0)\n",
        "        return X\n",
        "\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X = X.drop(columns=self.non_train_features)\n",
        "        for ftr in self.date_time_features:\n",
        "            X[ftr] = dt_to_seconds(X[ftr])\n",
        "            if X[ftr].isna().sum() > 0:\n",
        "                new_ftr = ftr + '_missing'\n",
        "                X[new_ftr] = X[ftr].isna().astype(int)\n",
        "                X[ftr] = X[ftr].fillna(-1)\n",
        "        \n",
        "        X[self.numerical_features] = self.scaler.transform(X[self.numerical_features])\n",
        "        ohe_feature_names = self.encoder.get_feature_names_out()\n",
        "        X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
        "        X = X.drop(columns=self.categorical_features)\n",
        "        for col in ['r_days_from_arrest', 'violent_recid']:\n",
        "            if col in X.columns:\n",
        "                X[col] = X[col].fillna(0)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkgRPopIxNVJ"
      },
      "source": [
        "### **4. Train and test split**\n",
        "\n",
        "Divide the dataset into a train (80%) and test split (20%), either by implementing it yourself, or by using an existing library.\n",
        "\n",
        "**Note:** Usually when carrying out machine learning experiments,\n",
        "we also need a dev set for developing and selecting our models (incl. tuning of hyper-parameters).\n",
        "However, in this assignment, the goal is not to optimize\n",
        "the performance of models so we'll only use a train and test split.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "G0wUGEpiV7mH"
      },
      "outputs": [],
      "source": [
        "X, y = compas_data.drop(columns=['two_year_recid']), compas_data['two_year_recid']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/sklearn/utils/extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "/var/folders/wl/tkx29dw96sbgly88cthpjgzc0000gn/T/ipykernel_35310/273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n"
          ]
        }
      ],
      "source": [
        "processor = FeaturePreprocessor(categorical_features, date_time_features, non_train_features)\n",
        "X_train = processor.fit_transform(X_train, X[categorical_features])\n",
        "X_test = processor.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmq45GgAWEJo"
      },
      "source": [
        "### **5. Classifiers**\n",
        "\n",
        "Now, train and test different classifiers and report the following statistics:\n",
        "\n",
        "* Overall precision, recall, F1 and accuracy;\n",
        "* The statistical parity difference for the protected attribute (difference between the probability of a favorable label);\n",
        "* The true positive rates and the false positive rates of the two protected attribute groups.\n",
        "\n",
        "For training the classifier we recommend using scikit-learn (https://scikit-learn.org/stable/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu6eQ_3xGfXd"
      },
      "source": [
        "#### **5.1 Regular classification**\n",
        "Train a logistic regression classifier with the race feature and all other features that you are interested in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "xDaGo07EWElK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.982,\n",
              " 'precision': 0.976,\n",
              " 'recall': 0.9859,\n",
              " 'f1': 0.9809,\n",
              " 'disparate_impact': 0.0,\n",
              " 'demographic_parity': 1,\n",
              " 'African-American_true_positive_rate': 0.0,\n",
              " 'Caucasian_true_positive_rate': 0.9755,\n",
              " 'equal_opportunity': 1,\n",
              " 'African-American_false_positive_rate': 0.0,\n",
              " 'Caucasian_false_positive_rate': 0.0204,\n",
              " 'predictive_parity': 1}"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logreg = LogisticRegression(random_state=SEED)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "test_res_df = X_test.copy()\n",
        "test_res_df['race'] = 'Afracan-American'\n",
        "test_res_df.loc[test_res_df['race_Caucasian'] == 1, 'race'] = 'Caucasian'\n",
        "test_res_df['two_year_recid'] = y_test\n",
        "\n",
        "test_res_df['prediction'] = y_pred\n",
        "metrics(test_res_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM23AP8nFisw"
      },
      "source": [
        "#### **5.2 Without the protected attribute**\n",
        "Train a logistic regression classifier without the race feature, but with all other features you used in 5.1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "WL7LSSMPFmhv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.9811,\n",
              " 'precision': 0.976,\n",
              " 'recall': 0.9839,\n",
              " 'f1': 0.9799,\n",
              " 'disparate_impact': 0.0,\n",
              " 'demographic_parity': 1,\n",
              " 'African-American_true_positive_rate': 0.0,\n",
              " 'Caucasian_true_positive_rate': 0.9755,\n",
              " 'equal_opportunity': 1,\n",
              " 'African-American_false_positive_rate': 0.0,\n",
              " 'Caucasian_false_positive_rate': 0.0204,\n",
              " 'predictive_parity': 1}"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_protected = X_train.drop(['race_African-American', 'race_Caucasian'], axis=1)\n",
        "X_test_protected = X_test.drop(['race_African-American', 'race_Caucasian'], axis=1)\n",
        "\n",
        "logreg = LogisticRegression(random_state=SEED)\n",
        "logreg.fit(X_train_protected, y_train)\n",
        "y_pred = logreg.predict(X_test_protected)\n",
        "\n",
        "test_res_df['prediction'] = y_pred\n",
        "metrics(test_res_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwiX0vEXFlgU"
      },
      "source": [
        "#### **5.3 Pre-processing: Reweighing**\n",
        "Train a classifier with weights (see lecture slides the weight calculation)\n",
        "* Report the weights that are used for reweighing and a short interpretation/discussion.\n",
        "* Hint: Think about when you should reweight the data: during initialization or during training (i.e. fit)? Read the documentation of the Logistic regression model in Scikit-learn carefully (if you use it)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "G-1Vw1_xk4aQ"
      },
      "outputs": [],
      "source": [
        "data = X_train.copy()\n",
        "data['outcome'] = y_train\n",
        "\n",
        "# Calculate the necessary proportions\n",
        "# Proportions of positive outcomes\n",
        "P_AA_pos = (data['race_African-American'] == 1) & (data['outcome'] == 0)\n",
        "P_C_pos = (data['race_Caucasian'] == 1) & (data['outcome'] == 0)\n",
        "\n",
        "# Proportions of negative outcomes\n",
        "P_AA_neg = (data['race_African-American'] == 1) & (data['outcome'] == 1)\n",
        "P_C_neg = (data['race_Caucasian'] == 1) & (data['outcome'] == 1)\n",
        "\n",
        "# Convert booleans to integers and calculate the proportion\n",
        "p1_pos = P_AA_pos.sum() / (data['race_African-American'] == 1).sum()\n",
        "p2_pos = P_C_pos.sum() / (data['race_Caucasian'] == 1).sum()\n",
        "p1_neg = P_AA_neg.sum() / (data['race_African-American'] == 1).sum()\n",
        "p2_neg = P_C_neg.sum() / (data['race_Caucasian'] == 1).sum()\n",
        "\n",
        "# Desired balance for each outcome across all groups\n",
        "total_pos = data['outcome'].value_counts(normalize=True)[0]  # total proportion of positive outcomes\n",
        "total_neg = data['outcome'].value_counts(normalize=True)[1]  # total proportion of negative outcomes\n",
        "\n",
        "# Calculate weights\n",
        "data['weight'] = np.where(data['race_African-American'] == 1,\n",
        "                          np.where(data['outcome'] == 0, (total_pos / p1_pos), (total_neg / p1_neg)),\n",
        "                          np.where(data['outcome'] == 0, (total_pos / p2_pos), (total_neg / p2_neg)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train_protected, y_train, sample_weight=data['weight'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.9801,\n",
              " 'precision': 0.976,\n",
              " 'recall': 0.9819,\n",
              " 'f1': 0.9789,\n",
              " 'disparate_impact': 0.0,\n",
              " 'demographic_parity': 1,\n",
              " 'African-American_true_positive_rate': 0.0,\n",
              " 'Caucasian_true_positive_rate': 0.9755,\n",
              " 'equal_opportunity': 1,\n",
              " 'African-American_false_positive_rate': 0.0,\n",
              " 'Caucasian_false_positive_rate': 0.0204,\n",
              " 'predictive_parity': 1}"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = logreg.predict(X_test_protected)\n",
        "\n",
        "test_res_df['prediction'] = y_pred\n",
        "metrics(test_res_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3XdW0qF82JC"
      },
      "source": [
        "#### **5.4 Post-processing: Equalized odds**\n",
        "Use the predictions by the first classifier for this post processing part (see lecture slides for more information about post processing for equalized odds).\n",
        "\n",
        "Normally, the best parameters `p_00, p_01, p_10, p_11` are found with a linear program that minimizes loss between predictions of a derived predictor and the actual labels. In this assignment we will not ask you to do this. Instead, we would like you to follow the next steps to find parameters, post-process the data and check the performance of this classifier with post-processing:\n",
        "\n",
        "1. Generate a 1000 different samples of these 4 parameters randomly;\n",
        "2. Write a function (or more) that applies these 4 parameters to postprocess the predictions.\n",
        "3. For each generated set of 4 parameters:\n",
        "  - Change the predicted labels with the function(s) from step 2;\n",
        "  - Calculate the TPR ratio and FPR ratio over these 'new' predictions;\n",
        "4. Which set of parameters satisfies the equalized odds fairness measure the best?\n",
        "5. Check the overall performance (precision, recall, accuracy, etc.) of the new predictions after post-processing and add an interpretation of the results and the parameters in your **report**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk_scQdM76He"
      },
      "outputs": [],
      "source": [
        "# Your code for step 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0p92txObr6v"
      },
      "outputs": [],
      "source": [
        "# Your code for step 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teZWyupiw2iM"
      },
      "outputs": [],
      "source": [
        "# Your code for step 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q-t-ZljWBBS9"
      },
      "outputs": [],
      "source": [
        "# Your code for step 4 and 5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD0weMlkN4Cq"
      },
      "source": [
        "#### **Results**\n",
        "For each classifier write in the **report**:\n",
        "- Whether this classifier satisfies statistical parity and whether this compares to the original dataset;\n",
        "- Does the classifier satisfy the equal opportunity criterion?\n",
        "- How do the different classifiers compare against each other?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUPZN32kOJ9H"
      },
      "source": [
        "### **6. Intersectional fairness**\n",
        "In the questions above `race` was the only protected attribute. However, multiple protected attributes sometimes interact, leading to different fairness outcomes for different combinations of these protected attributes.\n",
        "\n",
        "Please explore the intersectional fairness for protected attributes `race` and `sex` for the first two classifiers from question 5: instead of only reporting the statistical parity, TPR and FPR for the protected attribute race, make a combination of the `race` and `sex` column, with four categories of this combined protected attribute, and report the maximum difference between the subgroups for statistical parity, TPR and FPR. \n",
        "For example, suppose we have four groups with TPRs 0.1, 0.2, 0.8, then the maximum difference is 0.7.\n",
        "- For classifier 1: evaluate the predictions for this combined protected attribute;\n",
        "- For classifier 2: remove both `race` and `sex` from the data and check the results again.\n",
        "\n",
        "Write a short interpretation of these results in your **report**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSXG9sBjT-xX"
      },
      "outputs": [],
      "source": [
        "# Your code for intersectional fairness\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lfFYnU1V_bl"
      },
      "source": [
        "## Discussion\n",
        "Include a short ethical discussion (1 or 2 paragraphs) in your **report** reflecting on these two aspects:\n",
        "\n",
        "1) The use of a ML system to try to predict recidivism;\n",
        "\n",
        "2) The public release of a dataset like this."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
