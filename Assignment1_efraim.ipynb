{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvGd4YgtppjR"
      },
      "source": [
        "## Submission instructions\n",
        "\n",
        "All code that you write should be in this notebook. Please include your names and student numbers. You have to submit two files:\n",
        "\n",
        "* This notebook with your code added. Make sure to add enough documentation.\n",
        "* A short report, around 2 pages including any figures and/or tables (it is likely that you won't need the full 2 pages). Use [this template](https://www.overleaf.com/read/mvskntycrckw).\n",
        "\n",
        "For questions, make use of the \"Lab\" session (see schedule).\n",
        "Questions can also be posted to the MS teams channel called \"Lab\".\n",
        "\n",
        "**Note:** You are free to make use of Python libraries (e.g., numpy, sklearn, etc.) except any *fairness* libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bii8KkkLUg5i"
      },
      "source": [
        "#### Name and student numbers\n",
        "...\n",
        "Timofey Senchenko (), Efraim Dahl (1695568)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ni3V-7iqA6X"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "In this assignment we are going to use the **COMPAS** dataset.\n",
        "\n",
        "If you haven't done so already, take a look at this article: https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.\n",
        "For background on the dataset, see https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm.\n",
        "\n",
        "**Reading in the COMPAS dataset**\n",
        "\n",
        "The dataset can be downloaded here: https://github.com/propublica/compas-analysis/blob/master/compas-scores-two-years.csv\n",
        "\n",
        "For this assignment, we focus on the protected attribute *race*.\n",
        "\n",
        "The label (the variable we want to be able to predict) represents recidivism, which is defined as a new arrest within 2 years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajLXEdx6plgP",
        "outputId": "a65bf36a-1bc6-488f-accc-7bd9b24ca411"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget -c https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "AaT9DQwwpqkx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import seaborn as sns\n",
        "import random\n",
        "\n",
        "def set_seed(seed):\n",
        "    #set all random seeds\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    return None\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "set_seed(SEED)\n",
        "compas_data = pd.read_csv('compas-scores-two-years.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsidUr4Bz-gZ"
      },
      "source": [
        "We apply several data preprocessing steps, including only retaining Caucasians and African Americans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "vs2eRxdgrHrt"
      },
      "outputs": [],
      "source": [
        "compas_data = compas_data[(compas_data.days_b_screening_arrest <= 30)\n",
        "            & (compas_data.days_b_screening_arrest >= -30)\n",
        "            & (compas_data.is_recid != -1)\n",
        "            & (compas_data.c_charge_degree != 'O')\n",
        "            & (compas_data.score_text != 'N/A')\n",
        "            & ((compas_data.race == 'Caucasian') | (compas_data.race == 'African-American'))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5IwB6Rz2zIS"
      },
      "source": [
        "Take a look at the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMM-MYdstObf",
        "outputId": "0bf826a7-bf28-433b-ea6a-b21c5f3f1fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    id              name      first    last compas_screening_date     sex  \\\n",
            "1    3       kevon dixon      kevon   dixon            2013-01-27    Male   \n",
            "2    4          ed philo         ed   philo            2013-04-14    Male   \n",
            "6    8     edward riddle     edward  riddle            2014-02-19    Male   \n",
            "8   10  elizabeth thieme  elizabeth  thieme            2014-03-16  Female   \n",
            "10  14    benjamin franc   benjamin   franc            2013-11-26    Male   \n",
            "\n",
            "           dob  age       age_cat              race  ...  v_decile_score  \\\n",
            "1   1982-01-22   34       25 - 45  African-American  ...               1   \n",
            "2   1991-05-14   24  Less than 25  African-American  ...               3   \n",
            "6   1974-07-23   41       25 - 45         Caucasian  ...               2   \n",
            "8   1976-06-03   39       25 - 45         Caucasian  ...               1   \n",
            "10  1988-06-01   27       25 - 45         Caucasian  ...               4   \n",
            "\n",
            "    v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
            "1            Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
            "2            Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
            "6            Low        2014-02-19  2014-03-31   2014-04-18              14   \n",
            "8            Low        2014-03-16  2014-03-15   2014-03-18               0   \n",
            "10           Low        2013-11-26  2013-11-25   2013-11-26               0   \n",
            "\n",
            "   start  end event two_year_recid  \n",
            "1      9  159     1              1  \n",
            "2      0   63     0              1  \n",
            "6      5   40     1              1  \n",
            "8      2  747     0              0  \n",
            "10     0  857     0              0  \n",
            "\n",
            "[5 rows x 53 columns]\n"
          ]
        }
      ],
      "source": [
        "print(compas_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vKapT6FtmvJ"
      },
      "source": [
        "Now take a look at the distribution of the protected attribute `race` and the distribution of our outcome variable `two_year_recid`.\n",
        "\n",
        "**Note:** in the context of fair machine learning, the favorable label here is no recidivism, i.e., ```two_year_recid = 0```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh2oM2yptnjR",
        "outputId": "f89ff857-41d9-4a8c-d236-6fd4af65f177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of instances per race category:\n",
            "race              two_year_recid\n",
            "African-American  1                 1661\n",
            "                  0                 1514\n",
            "Caucasian         0                 1281\n",
            "                  1                  822\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Number of instances per race category:')\n",
        "print(compas_data[['race', 'two_year_recid']].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "636Yopp6wNtY"
      },
      "source": [
        "## Data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS3g2NT98dY_"
      },
      "source": [
        "### **1. Exploration**\n",
        "\n",
        "Perform an exploratory analysis of your data and describe the results in your report.\n",
        "Include at least the following:\n",
        "\n",
        "1. The size of your data;\n",
        "2. The size of the protected attribute classes;\n",
        "3. The base rates (the probability of a favorable outcome for the two protected attribute classes);\n",
        "4. The base rates for the combination of both race and sex categories. What do you see?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "k6FESAE1VmPu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Size: 5278\n",
            "Size of class  African-American : 3175\n",
            "Base rate African-American: 0.4768503937007874\n",
            "Base rate African-American (Male): 0.44478293983244477\n",
            "Base rate African-American (Female): 0.6302367941712204\n",
            "Size of class  Caucasian : 2103\n",
            "Base rate Caucasian: 0.609129814550642\n",
            "Base rate Caucasian (Male): 0.5977791486736582\n",
            "Base rate Caucasian (Female): 0.6473029045643154\n"
          ]
        }
      ],
      "source": [
        "data_size = len(compas_data)\n",
        "\n",
        "print(\"Data Size:\", data_size)\n",
        "\n",
        "vals = dict(compas_data[['race']].value_counts())\n",
        "svals = dict(compas_data[['sex']].value_counts())\n",
        "\n",
        "labels = [\"Race\",\"Sex\",\"Recidivism\"]\n",
        "rows=[]\n",
        "\n",
        "bb_rate = compas_data.loc[(compas_data['two_year_recid']==0)].shape[0]\n",
        "bb_frac = bb_rate/data_size\n",
        "rows.append(['*All Races','*All Sexes',bb_frac])\n",
        "\n",
        "for sval,num in svals.items():\n",
        "    recid2 = compas_data.loc[(compas_data['sex']==sval[0]) &(compas_data['two_year_recid']==0)].shape[0]\n",
        "    snum2 = compas_data.loc[(compas_data['sex']==sval[0])].shape[0]\n",
        "    frac = str(recid2/snum2)\n",
        "    rows.append(['*All Races',sval[0],frac])\n",
        "        \n",
        "    \n",
        "for val,num in vals.items():\n",
        "    #print(val,num)\n",
        "    recid = compas_data.loc[(compas_data['race']==val[0]) & (compas_data['two_year_recid']==0)].shape[0]\n",
        "    #rint(recid)\n",
        "    frac = str(recid/num)\n",
        "    print(\"Size of class \", val[0],\":\",num)\n",
        "    print(f'Base rate {val[0]}: {frac}')\n",
        "    rows.append([val[0],\"*All Sexes\",frac])\n",
        "    for sval,_ in svals.items():\n",
        "        #Combined Sex and Race\n",
        "        recid = compas_data.loc[(compas_data['race']==val[0]) & (compas_data['sex']==sval[0]) &(compas_data['two_year_recid']==0)].shape[0]\n",
        "        snum = compas_data.loc[(compas_data['race']==val[0]) & (compas_data['sex']==sval[0])].shape[0]\n",
        "        frac = str(recid/snum)\n",
        "        print(f'Base rate {val[0]} ({sval[0]}): {frac}')\n",
        "        rows.append([val[0],sval[0],frac])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sex               *All Sexes    Female      Male\n",
            "Race                                            \n",
            "*All Races          0.529557  0.638215  0.503179\n",
            "African-American    0.476850  0.630237  0.444783\n",
            "Caucasian           0.609130  0.647303  0.597779\n",
            "Sex               *All Sexes    Female      Male\n",
            "Race                                            \n",
            "*All Races          0.529557  0.638215  0.503179\n",
            "African-American    0.476850  0.630237  0.444783\n",
            "Caucasian           0.609130  0.647303  0.597779\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "df = pd.DataFrame(rows,columns=labels)\n",
        "df['Recidivism'] = pd.to_numeric(df['Recidivism'])\n",
        "\n",
        "df=df.pivot(index=\"Race\",columns=\"Sex\",values=\"Recidivism\")\n",
        "print(df)\n",
        "# replace the Month with year \n",
        "df = df.rename(columns={\"Race\":\"Sex\"})\n",
        "# drop first column\n",
        "#df = df.iloc[0:].reset_index(drop=True)\n",
        "\n",
        "print(df)\n",
        "sns.heatmap(df, annot=True, cmap=\"YlGnBu\", fmt='.2f')\n",
        "\n",
        "plt.title('Heatmap of Positive Outcomes by Sex and Race')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-mxqnnUcaGc"
      },
      "source": [
        "### **2. Performance measures**\n",
        "\n",
        "You will have to measure the performance and fairness of different classifiers in question 5. The performance will be calculated with the precision, recall, F1 and accuracy.\n",
        "Additionally, you will have to calculate the statistical/demographic parity, the true positive rate (recall) and false positive rate per race group.\n",
        "\n",
        "Make sure that you are able to calculate these metrics in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "IAO99gf2caZT"
      },
      "outputs": [],
      "source": [
        "# Your code for the performance measures\n",
        "# Your code for the performance measures\n",
        "def metrics(df, groups='race', disparity_threshold=0.8,prediction_column='prediction'):\n",
        "    '''\n",
        "    df: pandas DataFrame, must contain columns two_year_recid, prediction and column specified in groups (default \"race\")\n",
        "    returns: dictionary with performance metrics\n",
        "    '''\n",
        "    performance = {}\n",
        "    performance['accuracy'] = accuracy_score(df['two_year_recid'], df[prediction_column])\n",
        "    performance['precision'], performance['recall'], performance['f1'], _ = precision_recall_fscore_support(df['two_year_recid'], df[prediction_column], average='binary')\n",
        "    aa_group = df[df[groups] == 'African-American']\n",
        "    cc_group = df[df[groups] == 'Caucasian']\n",
        "    P_pos_aa = aa_group[aa_group[prediction_column] == 0].shape[0] / aa_group.shape[0]\n",
        "    P_pos_cc = cc_group[cc_group[prediction_column] == 0].shape[0] / cc_group.shape[0]\n",
        "    performance['disparate_impact'] = P_pos_aa/P_pos_cc\n",
        "    performance['demographic_parity'] = P_pos_aa/P_pos_cc < disparity_threshold\n",
        "\n",
        "    TP_rate_aa = aa_group[(aa_group[prediction_column] == 0) & (aa_group['two_year_recid'] == 0)].shape[0] / aa_group[aa_group['two_year_recid'] == 0].shape[0]\n",
        "    TP_rate_cc = cc_group[(cc_group[prediction_column] == 0) & (cc_group['two_year_recid'] == 0)].shape[0] / cc_group[cc_group['two_year_recid'] == 0].shape[0]\n",
        "\n",
        "    performance['African-American_true_positive_rate'] = TP_rate_aa\n",
        "    performance['Caucasian_true_positive_rate'] = TP_rate_cc\n",
        "    performance['equal_opportunity'] = TP_rate_aa/TP_rate_cc < disparity_threshold\n",
        "\n",
        "    FP_rate_aa = aa_group[(aa_group[prediction_column] == 0) & (aa_group['two_year_recid'] == 1)].shape[0] / aa_group[aa_group['two_year_recid'] == 0].shape[0]\n",
        "    FP_rate_cc = cc_group[(cc_group[prediction_column] == 0) & (cc_group['two_year_recid'] == 1)].shape[0] / cc_group[cc_group['two_year_recid'] == 0].shape[0]\n",
        "\n",
        "    performance['African-American_false_positive_rate'] = FP_rate_aa\n",
        "    performance['Caucasian_false_positive_rate'] = FP_rate_cc\n",
        "    performance['predictive_parity'] = FP_rate_aa/FP_rate_cc < disparity_threshold\n",
        "\n",
        "    # round to 4 decimal places\n",
        "    for key in performance.keys():\n",
        "        performance[key] = round(performance[key], 4)\n",
        "\n",
        "    return performance  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.5064,\n",
              " 'precision': 0.4768,\n",
              " 'recall': 0.5046,\n",
              " 'f1': 0.4903,\n",
              " 'disparate_impact': 0.9967,\n",
              " 'demographic_parity': 0,\n",
              " 'African-American_true_positive_rate': 0.5099,\n",
              " 'Caucasian_true_positive_rate': 0.5059,\n",
              " 'equal_opportunity': 0,\n",
              " 'African-American_false_positive_rate': 0.5416,\n",
              " 'Caucasian_false_positive_rate': 0.3201,\n",
              " 'predictive_parity': 0}"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# example usage\n",
        "compas_data['prediction'] = np.random.randint(0, 2, compas_data.shape[0])\n",
        "\n",
        "metrics(compas_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n51Bdpy59vhy"
      },
      "source": [
        "### **3. Prepare the data**\n",
        "For the classifiers in question 5, the input of the model can only contain numerical values, it is therefore important to convert the strings in the columns (features) of interest of the `compas_data` to floats or integers.\n",
        "\n",
        "The columns of interest are features that you think will be informative or interesting in predicting the outcome variable.\n",
        "\n",
        "Use the cell below to explore which of the compas variables you need to convert to be able to use them for the classifiers. Also make sure that you understand the relationship between categorical and numerical values.\n",
        "\n",
        "Then generate a new dataframe with your selected features in the right encoding (also make sure to include `two_year_recid`). You can implement this yourself, or use the `LabelEncoder` from `sklearn`.\n",
        "\n",
        "**Note:** you do not need to convert all columns/features, only the ones you are interested in. Please include in your **report** a short motivation (one-two sentence) per feature why you think this is informative or interesting to take into account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "2G0-QxbH95rX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initial dataset dat atypes id                           int64\n",
            "name                        object\n",
            "first                       object\n",
            "last                        object\n",
            "compas_screening_date       object\n",
            "sex                         object\n",
            "dob                         object\n",
            "age                          int64\n",
            "age_cat                     object\n",
            "race                        object\n",
            "juv_fel_count                int64\n",
            "decile_score                 int64\n",
            "juv_misd_count               int64\n",
            "juv_other_count              int64\n",
            "priors_count                 int64\n",
            "days_b_screening_arrest    float64\n",
            "c_jail_in                   object\n",
            "c_jail_out                  object\n",
            "c_case_number               object\n",
            "c_offense_date              object\n",
            "c_arrest_date               object\n",
            "c_days_from_compas         float64\n",
            "c_charge_degree             object\n",
            "c_charge_desc               object\n",
            "is_recid                     int64\n",
            "r_case_number               object\n",
            "r_charge_degree             object\n",
            "r_days_from_arrest         float64\n",
            "r_offense_date              object\n",
            "r_charge_desc               object\n",
            "r_jail_in                   object\n",
            "r_jail_out                  object\n",
            "violent_recid              float64\n",
            "is_violent_recid             int64\n",
            "vr_case_number              object\n",
            "vr_charge_degree            object\n",
            "vr_offense_date             object\n",
            "vr_charge_desc              object\n",
            "type_of_assessment          object\n",
            "decile_score.1               int64\n",
            "score_text                  object\n",
            "screening_date              object\n",
            "v_type_of_assessment        object\n",
            "v_decile_score               int64\n",
            "v_score_text                object\n",
            "v_screening_date            object\n",
            "in_custody                  object\n",
            "out_custody                 object\n",
            "priors_count.1               int64\n",
            "start                        int64\n",
            "end                          int64\n",
            "event                        int64\n",
            "two_year_recid               int64\n",
            "prediction                   int32\n",
            "dtype: object\n",
            "list of non numerical features: Index(['name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
            "       'age_cat', 'race', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
            "       'c_offense_date', 'c_arrest_date', 'c_charge_degree', 'c_charge_desc',\n",
            "       'r_case_number', 'r_charge_degree', 'r_offense_date', 'r_charge_desc',\n",
            "       'r_jail_in', 'r_jail_out', 'vr_case_number', 'vr_charge_degree',\n",
            "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment', 'score_text',\n",
            "       'screening_date', 'v_type_of_assessment', 'v_score_text',\n",
            "       'v_screening_date', 'in_custody', 'out_custody'],\n",
            "      dtype='object')\n",
            "list of categorical features: ['vr_case_number', 'v_type_of_assessment', 'c_charge_desc', 'r_charge_desc', 'score_text', 'age_cat', 'last', 'race', 'r_charge_degree', 'type_of_assessment', 'sex', 'v_score_text', 'vr_charge_desc', 'name', 'vr_charge_degree', 'first', 'c_charge_degree']\n"
          ]
        }
      ],
      "source": [
        "# Your code to prepare the data\n",
        "# print data type of each column\n",
        "print('initial dataset dat atypes', compas_data.dtypes)\n",
        "\n",
        "obj_features = compas_data.select_dtypes(include='object').columns\n",
        "print('list of non numerical features:', obj_features)\n",
        "\n",
        "date_time_features = ['compas_screening_date', 'dob', 'c_jail_in', 'c_jail_out',\n",
        "       'c_offense_date', 'c_arrest_date', 'r_offense_date',\n",
        "       'r_jail_in', 'r_jail_out', 'vr_offense_date', 'screening_date', 'v_screening_date', 'in_custody', 'out_custody']\n",
        "non_train_features = ['id', 'c_case_number', 'r_case_number']\n",
        "\n",
        "categorical_features = list(set(obj_features) - set(date_time_features) - set(non_train_features))\n",
        "categorical_features\n",
        "print('list of categorical features:', categorical_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "compas_screening_date       0\n",
              "dob                         0\n",
              "c_jail_in                   0\n",
              "c_jail_out                  0\n",
              "c_offense_date            689\n",
              "c_arrest_date            4589\n",
              "r_offense_date           2631\n",
              "r_jail_in                3497\n",
              "r_jail_out               3497\n",
              "vr_offense_date          4666\n",
              "screening_date              0\n",
              "v_screening_date            0\n",
              "in_custody                  0\n",
              "out_custody                 0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compas_data[date_time_features].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dt_to_seconds(series):\n",
        "    series = pd.to_datetime(series)\n",
        "    return (series - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
        "\n",
        "class FeaturePreprocessor:\n",
        "    def __init__(self, categorical_features, date_time_features, non_train_features, min_freq=0.01):\n",
        "        self.categorical_features = categorical_features\n",
        "        self.date_time_features = date_time_features\n",
        "        self.non_train_features = non_train_features\n",
        "        self.scaler = StandardScaler()\n",
        "        self.encoder = OneHotEncoder(sparse_output=False, min_frequency=min_freq)\n",
        "\n",
        "    def fit_transform(self, X, full_cetagorical_df):\n",
        "        X = X.copy()\n",
        "        X = X.drop(columns=self.non_train_features)\n",
        "        self.numerical_features = list(set(X.columns) - set(self.categorical_features))\n",
        "        for ftr in self.date_time_features:\n",
        "            X[ftr] = dt_to_seconds(X[ftr])\n",
        "            if X[ftr].isna().sum() > 0:\n",
        "                new_ftr = ftr + '_missing'\n",
        "                X[new_ftr] = X[ftr].isna().astype(int)\n",
        "                X[ftr] = X[ftr].fillna(-1)\n",
        "        \n",
        "        X[self.numerical_features] = self.scaler.fit_transform(X[self.numerical_features])\n",
        "        self.encoder.fit(full_cetagorical_df)\n",
        "        ohe_feature_names = self.encoder.get_feature_names_out()\n",
        "        X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
        "        X = X.drop(columns=self.categorical_features)\n",
        "        for col in ['r_days_from_arrest', 'violent_recid']:\n",
        "            if col in X.columns:\n",
        "                X[col] = X[col].fillna(0)\n",
        "        return X\n",
        "\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X = X.drop(columns=self.non_train_features)\n",
        "        for ftr in self.date_time_features:\n",
        "            X[ftr] = dt_to_seconds(X[ftr])\n",
        "            if X[ftr].isna().sum() > 0:\n",
        "                new_ftr = ftr + '_missing'\n",
        "                X[new_ftr] = X[ftr].isna().astype(int)\n",
        "                X[ftr] = X[ftr].fillna(-1)\n",
        "        \n",
        "        X[self.numerical_features] = self.scaler.transform(X[self.numerical_features])\n",
        "        ohe_feature_names = self.encoder.get_feature_names_out()\n",
        "        X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
        "        X = X.drop(columns=self.categorical_features)\n",
        "        for col in ['r_days_from_arrest', 'violent_recid']:\n",
        "            if col in X.columns:\n",
        "                X[col] = X[col].fillna(0)\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkgRPopIxNVJ"
      },
      "source": [
        "### **4. Train and test split**\n",
        "\n",
        "Divide the dataset into a train (80%) and test split (20%), either by implementing it yourself, or by using an existing library.\n",
        "\n",
        "**Note:** Usually when carrying out machine learning experiments,\n",
        "we also need a dev set for developing and selecting our models (incl. tuning of hyper-parameters).\n",
        "However, in this assignment, the goal is not to optimize\n",
        "the performance of models so we'll only use a train and test split.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "G0wUGEpiV7mH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Programms\\Anaconda\\envs\\MEGDNN\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1051: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "d:\\Programms\\Anaconda\\envs\\MEGDNN\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1056: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "d:\\Programms\\Anaconda\\envs\\MEGDNN\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1076: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n",
            "C:\\Users\\Efraim\\AppData\\Local\\Temp\\ipykernel_2688\\273650697.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[ohe_feature_names] = self.encoder.transform(X[self.categorical_features])\n"
          ]
        }
      ],
      "source": [
        "# Your code to split the data\n",
        "X, y = compas_data.drop(columns=['two_year_recid']), compas_data['two_year_recid']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
        "\n",
        "processor = FeaturePreprocessor(categorical_features, date_time_features, non_train_features)\n",
        "X_train = processor.fit_transform(X_train, X[categorical_features])\n",
        "X_test = processor.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmq45GgAWEJo"
      },
      "source": [
        "### **5. Classifiers**\n",
        "\n",
        "Now, train and test different classifiers and report the following statistics:\n",
        "\n",
        "* Overall precision, recall, F1 and accuracy;\n",
        "* The statistical parity difference for the protected attribute (difference between the probability of a favorable label);\n",
        "* The true positive rates and the false positive rates of the two protected attribute groups.\n",
        "\n",
        "For training the classifier we recommend using scikit-learn (https://scikit-learn.org/stable/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu6eQ_3xGfXd"
      },
      "source": [
        "#### **5.1 Regular classification**\n",
        "Train a logistic regression classifier with the race feature and all other features that you are interested in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "xDaGo07EWElK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Programms\\Anaconda\\envs\\MEGDNN\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.9811,\n",
              " 'precision': 0.976,\n",
              " 'recall': 0.9839,\n",
              " 'f1': 0.9799,\n",
              " 'disparate_impact': 0.8213,\n",
              " 'demographic_parity': 0,\n",
              " 'African-American_true_positive_rate': 0.981,\n",
              " 'Caucasian_true_positive_rate': 0.9755,\n",
              " 'equal_opportunity': 0,\n",
              " 'African-American_false_positive_rate': 0.0095,\n",
              " 'Caucasian_false_positive_rate': 0.0204,\n",
              " 'predictive_parity': 1}"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code for classifier 1\n",
        "logreg_base = LogisticRegression(random_state=SEED)\n",
        "logreg_base.fit(X_train, y_train)\n",
        "y_pred_base = logreg_base.predict(X_test)\n",
        "test_res_df_base = X_test.copy()\n",
        "test_res_df_base['race'] = 'African-American'\n",
        "test_res_df_base.loc[test_res_df_base['race_Caucasian'] == 1, 'race'] = 'Caucasian'\n",
        "test_res_df_base['two_year_recid'] = y_test\n",
        "\n",
        "test_res_df_base['prediction'] = y_pred_base\n",
        "metrics(test_res_df_base)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM23AP8nFisw"
      },
      "source": [
        "#### **5.2 Without the protected attribute**\n",
        "Train a logistic regression classifier without the race feature, but with all other features you used in 5.1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "WL7LSSMPFmhv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Programms\\Anaconda\\envs\\MEGDNN\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.982,\n",
              " 'precision': 0.976,\n",
              " 'recall': 0.9859,\n",
              " 'f1': 0.9809,\n",
              " 'disparate_impact': 0.8187,\n",
              " 'demographic_parity': 0,\n",
              " 'African-American_true_positive_rate': 0.981,\n",
              " 'Caucasian_true_positive_rate': 0.9755,\n",
              " 'equal_opportunity': 0,\n",
              " 'African-American_false_positive_rate': 0.0063,\n",
              " 'Caucasian_false_positive_rate': 0.0204,\n",
              " 'predictive_parity': 1}"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code for classifier 2\n",
        "X_train_protected = X_train.drop(['race_African-American', 'race_Caucasian'], axis=1)\n",
        "X_test_protected = X_test.drop(['race_African-American', 'race_Caucasian'], axis=1)\n",
        "\n",
        "logreg = LogisticRegression(random_state=SEED)\n",
        "logreg.fit(X_train_protected, y_train)\n",
        "y_pred = logreg.predict(X_test_protected)\n",
        "test_res_df = test_res_df_base.copy()\n",
        "\n",
        "test_res_df['prediction'] = y_pred\n",
        "metrics(test_res_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwiX0vEXFlgU"
      },
      "source": [
        "#### **5.3 Pre-processing: Reweighing**\n",
        "Train a classifier with weights (see lecture slides the weight calculation)\n",
        "* Report the weights that are used for reweighing and a short interpretation/discussion.\n",
        "* Hint: Think about when you should reweight the data: during initialization or during training (i.e. fit)? Read the documentation of the Logistic regression model in Scikit-learn carefully (if you use it)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "G-1Vw1_xk4aQ"
      },
      "outputs": [],
      "source": [
        "# Your code for classifier 3\n",
        "data = X_train.copy()\n",
        "data['outcome'] = y_train\n",
        "\n",
        "# Calculate the necessary proportions\n",
        "# Proportions of positive outcomes\n",
        "P_AA_pos = (data['race_African-American'] == 1) & (data['outcome'] == 0)\n",
        "P_C_pos = (data['race_Caucasian'] == 1) & (data['outcome'] == 0)\n",
        "\n",
        "# Proportions of negative outcomes\n",
        "P_AA_neg = (data['race_African-American'] == 1) & (data['outcome'] == 1)\n",
        "P_C_neg = (data['race_Caucasian'] == 1) & (data['outcome'] == 1)\n",
        "\n",
        "# Convert booleans to integers and calculate the proportion\n",
        "p1_pos = P_AA_pos.sum() / (data['race_African-American'] == 1).sum()\n",
        "p2_pos = P_C_pos.sum() / (data['race_Caucasian'] == 1).sum()\n",
        "p1_neg = P_AA_neg.sum() / (data['race_African-American'] == 1).sum()\n",
        "p2_neg = P_C_neg.sum() / (data['race_Caucasian'] == 1).sum()\n",
        "\n",
        "# Desired balance for each outcome across all groups\n",
        "total_pos = data['outcome'].value_counts(normalize=True)[0]  # total proportion of positive outcomes\n",
        "total_neg = data['outcome'].value_counts(normalize=True)[1]  # total proportion of negative outcomes\n",
        "\n",
        "# Calculate weights\n",
        "data['weight'] = np.where(data['race_African-American'] == 1,\n",
        "                          np.where(data['outcome'] == 0, (total_pos / p1_pos), (total_neg / p1_neg)),\n",
        "                          np.where(data['outcome'] == 0, (total_pos / p2_pos), (total_neg / p2_neg)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Programms\\Anaconda\\envs\\MEGDNN\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train_protected, y_train, sample_weight=data['weight'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.9801,\n",
              " 'precision': 0.976,\n",
              " 'recall': 0.9819,\n",
              " 'f1': 0.9789,\n",
              " 'disparate_impact': 0.8239,\n",
              " 'demographic_parity': 0,\n",
              " 'African-American_true_positive_rate': 0.981,\n",
              " 'Caucasian_true_positive_rate': 0.9755,\n",
              " 'equal_opportunity': 0,\n",
              " 'African-American_false_positive_rate': 0.0127,\n",
              " 'Caucasian_false_positive_rate': 0.0204,\n",
              " 'predictive_parity': 1}"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = logreg.predict(X_test_protected)\n",
        "\n",
        "test_res_df['prediction'] = y_pred\n",
        "metrics(test_res_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3XdW0qF82JC"
      },
      "source": [
        "#### **5.4 Post-processing: Equalized odds**\n",
        "Use the predictions by the first classifier for this post processing part (see lecture slides for more information about post processing for equalized odds).\n",
        "\n",
        "Normally, the best parameters `p_00, p_01, p_10, p_11` are found with a linear program that minimizes loss between predictions of a derived predictor and the actual labels. In this assignment we will not ask you to do this. Instead, we would like you to follow the next steps to find parameters, post-process the data and check the performance of this classifier with post-processing:\n",
        "\n",
        "1. Generate a 1000 different samples of these 4 parameters randomly;\n",
        "2. Write a function (or more) that applies these 4 parameters to postprocess the predictions.\n",
        "3. For each generated set of 4 parameters:\n",
        "  - Change the predicted labels with the function(s) from step 2;\n",
        "  - Calculate the TPR ratio and FPR ratio over these 'new' predictions;\n",
        "4. Which set of parameters satisfies the equalized odds fairness measure the best?\n",
        "5. Check the overall performance (precision, recall, accuracy, etc.) of the new predictions after post-processing and add an interpretation of the results and the parameters in your **report**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "Nk_scQdM76He"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.64414922 0.04818601]\n",
            " [0.36005047 0.95679982]]\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Generate Random Parameter Samples\n",
        "NUM_GROUPS = 2\n",
        "NUM_PREDS = 2\n",
        "NUM_SAMPLES = 1000\n",
        "\n",
        "#Create random 3D array\n",
        "randParameters = np.random.rand(NUM_SAMPLES,NUM_GROUPS, NUM_PREDS)\n",
        "print(randParameters[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "W0p92txObr6v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  race  prediction  derived_prediction  two_year_recid\n",
            "14           Caucasian           1                   1               1\n",
            "5787  African-American           1                   0               0\n",
            "765   African-American           0                   1               0\n",
            "2465         Caucasian           1                   1               1\n",
            "5362  African-American           1                   1               1\n",
            "...                ...         ...                 ...             ...\n",
            "1609  African-American           0                   0               0\n",
            "1816         Caucasian           0                   1               0\n",
            "5270         Caucasian           0                   0               0\n",
            "454   African-American           0                   1               1\n",
            "395          Caucasian           0                   1               0\n",
            "\n",
            "[1056 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Apply parameters to post-process: Randomly change predictions based on group and predicted values from the classifier\n",
        "\n",
        "\n",
        "class DerivedClassifier:\n",
        "    def __init__(self,params):\n",
        "        self.params = params #[0.4,0.5,0.6,0.7]\n",
        "    def predict(self,prediction,group):\n",
        "       #set output randomly according to params\n",
        "        p = self.params[prediction,group]\n",
        "        if(np.random.random()<p):\n",
        "            return 0\n",
        "        else:\n",
        "            return 1        \n",
        "    def evaluate(self,df):\n",
        "        lis = []\n",
        "        for index, row in df.iterrows():\n",
        "            group = 0 if row['race']==\"Caucasian\" else 1\n",
        "            lis.append(self.predict(row['prediction'],group))\n",
        "        df['derived_prediction']=lis\n",
        "        return df\n",
        "\n",
        "\n",
        "#Testing the derived Classifier\n",
        "test_res_df_der = test_res_df_base.copy()\n",
        "#print(test_res_df_der)\n",
        "classif = DerivedClassifier(randParameters[0])\n",
        "#print(test_res_df_der)\n",
        "test_res_df_der = classif.evaluate(test_res_df_der)\n",
        "\n",
        "print(test_res_df_der[[\"race\",\"prediction\",\"derived_prediction\",\"two_year_recid\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.19201608 0.14602102]\n",
            " [0.93806414 0.91764728]]\n",
            "{'accuracy': 0.1402, 'precision': 0.0929, 'recall': 0.0948, 'f1': 0.0938, 'disparate_impact': 1.0726, 'demographic_parity': 0, 'African-American_true_positive_rate': 0.146, 'Caucasian_true_positive_rate': 0.2245, 'equal_opportunity': 1, 'African-American_false_positive_rate': 0.946, 'Caucasian_false_positive_rate': 0.6163, 'predictive_parity': 0}\n"
          ]
        }
      ],
      "source": [
        "#Step 3: For each of the 1000 random parameters, calculate TPR and FPR, minimize the difference between group TPRS for best equalized odds \n",
        "mindif = 1\n",
        "minParamDex = -1\n",
        "for i in range(0, len(randParameters)):\n",
        "    #Testing the derived Classifier\n",
        "    test_res_df_der = test_res_df_base.copy()\n",
        "    classif = DerivedClassifier(randParameters[0])\n",
        "    test_res_df_der = classif.evaluate(test_res_df_der)\n",
        "    performance = metrics(test_res_df_der, prediction_column=\"derived_prediction\")\n",
        "    curdifTPR = abs(performance['Caucasian_true_positive_rate']-performance['African-American_true_positive_rate'])\n",
        "    curdifFPR = abs(performance['Caucasian_false_positive_rate']-performance['African-American_false_positive_rate'])\n",
        "    curdif = curdifTPR+curdifFPR\n",
        "    if(curdif<mindif):\n",
        "        mindif=curdif\n",
        "        minParamDex = i\n",
        "\n",
        "#4 and 5\n",
        "#Testing the best results\n",
        "test_res_df_der = test_res_df_base.copy()\n",
        "#print(test_res_df_der)\n",
        "classif = DerivedClassifier(randParameters[minParamDex])\n",
        "#print(test_res_df_der)\n",
        "test_res_df_der = classif.evaluate(test_res_df_der)\n",
        "\n",
        "print(randParameters[minParamDex])\n",
        "print(metrics(test_res_df_der, prediction_column=\"derived_prediction\"))\n",
        "    \n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Best Results: \n",
        "[[0.28060081 0.34993785]\n",
        " [0.78242581 0.99251462]]\n",
        "{'accuracy': 0.2244, 'precision': 0.1218, 'recall': 0.1048, 'f1': 0.1127, 'disparate_impact': 1.3677, 'demographic_parity': 0, 'African-American_true_positive_rate': 0.3397, 'Caucasian_true_positive_rate': 0.3184, 'equal_opportunity': 0, 'African-American_false_positive_rate': 1.019, 'Caucasian_false_positive_rate': 0.502, 'predictive_parity': 0}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD0weMlkN4Cq"
      },
      "source": [
        "#### **Results**\n",
        "For each classifier write in the **report**:\n",
        "- Whether this classifier satisfies statistical parity and whether this compares to the original dataset;\n",
        "- Does the classifier satisfy the equal opportunity criterion?\n",
        "- How do the different classifiers compare against each other?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUPZN32kOJ9H"
      },
      "source": [
        "### **6. Intersectional fairness**\n",
        "In the questions above `race` was the only protected attribute. However, multiple protected attributes sometimes interact, leading to different fairness outcomes for different combinations of these protected attributes.\n",
        "\n",
        "Please explore the intersectional fairness for protected attributes `race` and `sex` for the first two classifiers from question 5: instead of only reporting the statistical parity, TPR and FPR for the protected attribute race, make a combination of the `race` and `sex` column, with four categories of this combined protected attribute, and report the maximum difference between the subgroups for statistical parity, TPR and FPR. \n",
        "For example, suppose we have four groups with TPRs 0.1, 0.2, 0.8, then the maximum difference is 0.7.\n",
        "- For classifier 1: evaluate the predictions for this combined protected attribute;\n",
        "- For classifier 2: remove both `race` and `sex` from the data and check the results again.\n",
        "\n",
        "Write a short interpretation of these results in your **report**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSXG9sBjT-xX"
      },
      "outputs": [],
      "source": [
        "# Your code for intersectional fairness\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lfFYnU1V_bl"
      },
      "source": [
        "## Discussion\n",
        "Include a short ethical discussion (1 or 2 paragraphs) in your **report** reflecting on these two aspects:\n",
        "\n",
        "1) The use of a ML system to try to predict recidivism;\n",
        "\n",
        "2) The public release of a dataset like this."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
