{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMSxpJAkqYzk"
      },
      "source": [
        "# Programming Assignment II: Explainability\n",
        "\n",
        "In this assignment you will train machine learning models and experiment with techniques discussed in the lectures.\n",
        "This assignment makes use of existing Python libraries for some questions. We have provided links to tutorials/examples if you're not familiar with them yet.\n",
        "\n",
        "All code that you implement should be in this notebook. You should submit:\n",
        "* This notebook with your code added. Make sure to add enough documentation. Also provide complete answers to the more theoretical questions in this notebook. These questions are followed by an 'answer indent':\n",
        "> Answer:\n",
        "\n",
        "The notebook .ipynb should have the name format `Prog_Explainability_Group_X.ipynb`, where X is your programming group ID.\n",
        "\n",
        "Important notes:\n",
        "* Deadline for this assignment is **Monday, June 3, 17:00**.\n",
        "* Send it to both Mart Koek (m.j.koek@uu.nl) and Heysem Kaya (h.kaya@uu.nl), CCing your programming partner.\n",
        "* Title of the email: [INFOMHCML] Explainability programming assignment submission X, with X the number of your group.\n",
        "* There will be a lab session to assist you with the assignment on **Thursday, May 30, between 13:15-15:00 at DALTON 500 - 6.27 and DALTON 500 - 7.27**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moyaViIx8WzS"
      },
      "source": [
        "### Installation\n",
        "\n",
        "For this assignment, we are going to use the following Python packages:\n",
        "graphviz, matplotlib, pandas, statsmodels, openpyxl, interpret, and scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EaC6P7RqXOh"
      },
      "source": [
        "# Installing packages\n",
        "!pip install graphviz\n",
        "!pip install matplotlib pandas statsmodels openpyxl\n",
        "!pip install interpret\n",
        "!pip install scikit-learn --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeSC0_WEpY0k"
      },
      "source": [
        "### Read the data\n",
        "We are going to use the ChaLearn LAP-FI (First Impressions) Dataset. This dataset contains 10.000 data points, which correspond to videos collected from YouTube and annotated via Amazon Mechanical Turk for the BIG-5 personality impressions: openness, extraversion, conscientiousness, neuroticism, agreeableness.\n",
        "\n",
        "These five personality impression scores will be used as features to predict the outcome variable: a job interview invitation.\n",
        "\n",
        "For a detailed description, see the [paper of the dataset](https://ieeexplore.ieee.org/abstract/document/7966041?casa_token=1Y03H5ykCqsAAAAA:VLhCcjAgByJ2hTdKhulmIUiXIVepEJfFyB7HM0XVts7bN8Gi8wMsiTT0qZ--I_kq8wiUHIpPN7es).\n",
        "\n",
        "\n",
        "1.   If you use Google Colab, upload 'all_df.csv' (you can find this file on blackboard) through the upload button in the Files tab.\n",
        "  - Copy the path of the file;\n",
        "  - Run the cell below with your path. This will ask you for permission to access your Google Drive files and then you can access the data.\n",
        "2.   If you are running this notebook at your own machine (jupyter notebook), locate the 'all_df.csv' file in the same folder this notebook exists. Then you can run the second cell below.\n",
        "\n",
        "   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell only if you use Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Make sure you uploaded all_df.csv to your Google Drive and change the path\n",
        "# to the directory it is located in (usually in content/gdrive/MyDrive/...)\n",
        "%cd  '/content/gdrive/MyDrive/HCML/Explainability'"
      ],
      "metadata": {
        "id": "okPuwNvww9F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fleSmPrE7UMT"
      },
      "source": [
        "# Run this cell (both when working locally or with Google Colab)\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"all_df.csv\")\n",
        "print(\"Data loaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQpW5C3Sg9YA"
      },
      "source": [
        "### Loading and preprocessing the data\n",
        "There are 6000, 2000 and 2000 examples for training, validation/development and test set respectively. In the data this is indicated by the feature `split`.\n",
        "\n",
        "The training set is used to train models, the validation/development set to optimize the models hyper-parameters, and the test set to evaluate the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JycjPmn_7p41"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# global variables\n",
        "FEATURE_NAMES = ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'openness']\n",
        "LABEL_NAME = 'interview'\n",
        "\n",
        "def load_data():\n",
        "    def split_feature_label(data_set):\n",
        "        features = data_set[FEATURE_NAMES]\n",
        "        labels = data_set[LABEL_NAME]\n",
        "        return features, labels\n",
        "\n",
        "    train_set = data[data['split'] == 'training']\n",
        "    val_set = data[data['split'] == 'validation']\n",
        "    test_set = data[data['split'] == 'test']\n",
        "\n",
        "    train_features, train_labels = split_feature_label(train_set)\n",
        "    val_features, val_labels = split_feature_label(val_set)\n",
        "    test_features, test_labels = split_feature_label(test_set)\n",
        "\n",
        "    return train_features, train_labels, val_features, \\\n",
        "        val_labels, test_features, test_labels\n",
        "\n",
        "# Load the data with the function above\n",
        "(train_features, train_labels, dev_features, \\\n",
        "        dev_labels, test_features, test_labels) = load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1. Different models"
      ],
      "metadata": {
        "id": "VbkcGeJT6stA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QabF2JOdMTI4"
      },
      "source": [
        "### **1. Linear Regression**\n",
        "\n",
        "Train a linear regression model (we recommend the `statsmodels.api` package with the ordinary least squares model `sm`).\n",
        "\n",
        "Hint: to get a linear regression model, you should manually add a constant variable (usually called bias or intercept - that has a fixed value of 1 for all instances) to the data, either by adding it column yourself or by using the `add_constant()` function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.1**\n",
        "\n",
        "Provide the $R^2$ (goodness of fit) statistic and for each feature (+ the bias variable), the following in tabular format:\n",
        "* Weight estimate (coef)\n",
        "* SE (standard error of estimates)\n",
        "* T-statistic\n",
        "\n",
        "Hint: You can print the summary of the model using `.summary()` to do this. This gives an extensive overview of the performance of a model."
      ],
      "metadata": {
        "id": "fg6Tc7uD6jL_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B91BszFhMStw"
      },
      "source": [
        "# We recommend the statsmodels package\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Your code to add a bias/intercept variable\n",
        "\n",
        "# Train the model and print out the summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.2**\n",
        "\n",
        "Which three features are the most important?\n",
        "\n",
        "> Answer:"
      ],
      "metadata": {
        "id": "lQSPWuVzNBmX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.3**\n",
        "\n",
        "How does the predicted 'interview' score change with an 0.1 increase of the 'conscientiousness' feature given that all other feature values remain the same?\n",
        "\n",
        "> Answer:"
      ],
      "metadata": {
        "id": "6miEyz_f66Ei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.4**\n",
        "\n",
        "Show bar graph illustrations of the feature effects for the first two validation set instances.\n",
        "\n",
        "> Answer:"
      ],
      "metadata": {
        "id": "7AlVsA0ZhWbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the Feature Effects\n",
        "\n",
        "# Show bar graphs"
      ],
      "metadata": {
        "id": "abB-9YswhkMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tj6Pri4HBeO"
      },
      "source": [
        "**Q1.5**\n",
        "\n",
        "Reflection: why would training a regression tree not work well for this dataset in terms of model interpretability? And under what conditions could the dataset be used with a decision tree to yield an interpretable model?\n",
        "\n",
        "> Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7r09mMfeo2k"
      },
      "source": [
        "### **2. Explainable Boosting Model**\n",
        "Train an Explainable Boosting Machine (EBM) with [InterpretML](https://interpret.ml/docs/ebm.html). EBM is a Generalized Additive Model (GAM) that is highly intelligible and explainable.\n",
        "\n",
        "The `interpret` package provides both global and local explanation functions: `explain_global()` and `explain_local()` can be used to interpret a ML model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.1**\n",
        "\n",
        "Visualize/provide global (model-wise) feature importances for EBM as a table or figure."
      ],
      "metadata": {
        "id": "YUxfqAHb7ZgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from interpret.glassbox import ExplainableBoostingRegressor\n",
        "from interpret import show\n",
        "\n",
        "# EBM Global feature importances"
      ],
      "metadata": {
        "id": "jbqYT0Wh34k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.2**\n",
        "\n",
        "What are the most important two features in EBM? Are they the same as in the linear model?\n",
        "\n",
        "> Answer:"
      ],
      "metadata": {
        "id": "9cJ1uiHf34_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, to have an idea how EBM treats the input and generates the explanation, visualize EBM local explanations on a synthetic instance generated from training set mean feature vector as input and training set mean response as output.\n",
        "\n"
      ],
      "metadata": {
        "id": "oUxRg7Xr7hr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EBM Local explanation for training set mean vector with corresponding training set mean label\n",
        "train_mean_x = pd.DataFrame(train_features.mean(axis=0)).T\n",
        "train_mean_y = pd.DataFrame([train_labels.mean()])\n",
        "\n",
        "print(train_mean_x)\n",
        "print(train_mean_y)"
      ],
      "metadata": {
        "id": "BieO0LiSceUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.3**\n",
        "\n",
        "Now, visualize local (instance-wise) feature importances for the first two instances of the development set."
      ],
      "metadata": {
        "id": "5TMeydtDsB35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EBM local explanations for the first two development set instances"
      ],
      "metadata": {
        "id": "ce00C36ilxxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.4**\n",
        "\n",
        "Let's compare these feature importances with the feature effects in question 1.4.\n",
        "\n",
        "* Are the feature contribution orderings the same in both models for the two instances?\n",
        "> Answer:\n",
        "\n",
        "* For the second example's explanation, why do you think the contribution of *conscientiousness* is positive, while the contribution of *agreeableness* is negative? (Hint: consider the feature values relative to the training set mean values you calculated / processed in the former subquestion.)\n",
        "> Answer:"
      ],
      "metadata": {
        "id": "bTFmCfAn5xQK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k7dAwTIfbsc"
      },
      "source": [
        "# Part 2. Model-Agnostic Methods for Interpreting/Explaining NN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Training Neural Networks**\n",
        "Train a one-layer Neural Network (multi-layer perceptron (MLP) Regressor, but with one layer) with the following settings:\n",
        "\n",
        "- Activation function: ReLU\n",
        "- Size of the hidden layer: 50 neurons\n",
        "- Recommended optimizer/solver: Adam\n",
        "\n",
        "For a tutorial see [Tutorial](https://scikit-learn.org/stable/modules/neural_networks_supervised.html).\n",
        "\n",
        "**Q3.1**\n",
        "\n",
        "Apply the trained neural network model to the development set to find the best hyperparameters (such as learning rate). Report the Root Mean Square Error (RMSE) performance measure.\n",
        "\n",
        "**Note.** A development set RMSE below 0.045 is reasonable, then you can apply the corresponding model on the test set in the next question."
      ],
      "metadata": {
        "id": "5EbowFSZAZj6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQjg_qtCf_WD"
      },
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "# Train the MLPRegressor and show RMSE on development set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.2**\n",
        "\n",
        "Now use the best settings to report the Root Mean Square Error (RMSE) performance measure on the test set.\n",
        "\n",
        "It is possible to use the combination of the training and development sets to retrain the model and report the test set performance. You can also use the model that was trained on the training set only."
      ],
      "metadata": {
        "id": "rQySPj5Nt_sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RMSE on test set"
      ],
      "metadata": {
        "id": "YxuJUUUnPgGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can analyze factors that influence the predictions. Both Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE) plots can be used to visualize and analyze interaction between the target response and a set of input features of interest.\n",
        "\n",
        "See the [Documentation](https://scikit-learn.org/stable/modules/partial_dependence.html) on how to use PDPs and ICEs.\n",
        "\n",
        "**Q3.3**\n",
        "\n",
        "Generate univariate and bivariate PDPs for the `conscientiousness` and `agreeableness` features with the neural network you trained above."
      ],
      "metadata": {
        "id": "huX2fiH1-Qir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "\n",
        "# PDPs"
      ],
      "metadata": {
        "id": "xqVV2yHdpSdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.4**\n",
        "\n",
        "What do these plots show?\n",
        "\n",
        "> Answer:\n",
        "\n",
        "**Q3.5**\n",
        "\n",
        "Now generate ICE plots for each feature."
      ],
      "metadata": {
        "id": "M584ROYo1czo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ICEs"
      ],
      "metadata": {
        "id": "ig_iwDVqQBdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.6**\n",
        "\n",
        "What can you conclude from ICE plots above?\n",
        "\n",
        "> Answer:"
      ],
      "metadata": {
        "id": "Y75fIVlY2abm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.7**\n",
        "\n",
        "Implement the PDF (Partial Dependence Function) for univariate analysis of the trained NN model.\n"
      ],
      "metadata": {
        "id": "r0NLZmwHv5tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def PDF(X, model, feature):\n",
        "  \"\"\"\n",
        "  Input   Dataset 'X', Model 'model', feature_name 'feature'\n",
        "  Output  x_values: independent variable values\n",
        "          f_values: corresponding output per x value\n",
        "  \"\"\"\n",
        "  # Note: uncomment the lines below and complete the right hand side (where you see '..' to set them to suitable values, respective explanations are provided for each variable\n",
        "  # num_samples = ..  # set the number of samples/steps to slice the range of the continuous feature, e.g., 100.\n",
        "  # min_val = ..      # minimum value of the given feature\n",
        "  # max_val = ..      # maximum value of the given feature\n",
        "  # step_size = ..    # see the algorithm in corresponsing lecture slides to calculate the step size as a function of the above variables\n",
        "  # x_values = ..     # x_values at which we will calculate the partial function of the given feature\n",
        "  # f_values = ..     # the calculated partial function values corresponding to x_values\n",
        "\n",
        "  # for k in range(num_samples - 1):\n",
        "    # Change part of the data according to the formula of PDF algorithm\n",
        "    # Let the model predict and calculate the f_value for this k\n",
        "\n",
        "  # return x_values, f_values"
      ],
      "metadata": {
        "id": "nyRSmdVD9LF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.8**\n",
        "\n",
        "Calculate and visualize the feature importances obtained by your PDF algorithm with a bar graph. How do we calculate the feature importance given the x_values and y_values of the PDF algorithm?"
      ],
      "metadata": {
        "id": "-erhkuKc9Lbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First calculate the x_values and f_values for each feature"
      ],
      "metadata": {
        "id": "wGZc06rb-ksR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import linregress\n",
        "\n",
        "# Fit a linear model per feature, what is the output of this linear model?"
      ],
      "metadata": {
        "id": "RwjNZFql9QtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.9**\n",
        "\n",
        "What are the two most important features obtained by the PDF algorithm for the MLP model? How do these two features compare to the top two features from the Linear Model and the EBM?\n",
        "\n",
        "> Answer:\n"
      ],
      "metadata": {
        "id": "4I5Z1dRl86BP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Permutation Feature Importance**\n",
        "\n",
        "**Q4.1**\n",
        "\n",
        "Implement the permutation feature importance algorithm using RMSE as the error function. No existing libraries (barring the RMSE from `sklearn` and a function for random sampling / permutation) are allowed to be used, you will implement it yourself with the framework below."
      ],
      "metadata": {
        "id": "T8slEz838w8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def PFI(X, labels, model, base_rmse):\n",
        "  results = []\n",
        "\n",
        "  for feature in X:\n",
        "    # Create a copy of X_test\n",
        "    # Scramble the values of the given predictor\n",
        "    # Calculate the new RMSE\n",
        "    # Append the increase in MSE to the list of results\n",
        "\n",
        "  # Put the results into a pandas dataframe and rank the predictors by score\n",
        "\n",
        "  # return results_df"
      ],
      "metadata": {
        "id": "S7xUqEYnv4wA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.2**\n",
        "\n",
        "Visualize the feature importances obtained by your PFI algorithm with a bar graph."
      ],
      "metadata": {
        "id": "BHemT4b73rwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar graph of feature importances"
      ],
      "metadata": {
        "id": "gxZ9pPBoVsdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.3**\n",
        "\n",
        "What are the two most important features obtained by the permutation feature importance algorithm for the MLP model? How do these two features compare to the top two features from the Linear Model and the EBM?\n",
        "\n",
        "> Answer:"
      ],
      "metadata": {
        "id": "qmvAN-wT336H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.4**\n",
        "\n",
        "Explain two disadvantages of the PFI method.\n",
        "\n",
        "> Answer:"
      ],
      "metadata": {
        "id": "Oq4CuON4vY2y"
      }
    }
  ]
}